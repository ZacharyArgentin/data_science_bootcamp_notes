{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887b5602",
   "metadata": {},
   "source": [
    "# PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706da768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd52c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/18 01:51:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "session = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7c9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = session.sparkContext.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f32579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring first 2 values of rdd to the driver\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37be568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the length of the rdd\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69839978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send all rdd data to the driver\n",
    "# be careful tho, make sure the big data is not too big\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0f98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = session.createDataFrame(\n",
    "    [[1,2,3], [4,5,6]], [\"col1\", \"col2\", \"col3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20e9f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[col1: bigint, col2: bigint, col3: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545f68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "+----+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8206632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0518e",
   "metadata": {},
   "source": [
    "RDD's and dataframes are immutable.  \n",
    "because concurrent processing often requires immutable data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd109e7",
   "metadata": {},
   "source": [
    "Transformations are lazy loaded, and they don't actually run until you consume their results via an action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf00ac",
   "metadata": {},
   "source": [
    "### dataframe manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2494489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as funcs\n",
    "import pyspark.sql.types as types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a7a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_ten(num):\n",
    "    return num*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e631c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----------+\n",
      "|col1|col2|col3|multiplied|\n",
      "+----+----+----+----------+\n",
      "|   1|   2|   3|      null|\n",
      "|   4|   5|   6|      null|\n",
      "+----+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# udf stands for user defined function\n",
    "multiply_udf = funcs.udf(multiply_by_ten, types.DoubleType())\n",
    "\n",
    "transformed_df = df.withColumn('multiplied', multiply_udf('col1'))\n",
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa05dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "257d0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_log_in_all_columns(row: types.Row):\n",
    "     old_row = row.asDict()\n",
    "     new_row = {f'log({column_name})': math.log(value) \n",
    "                for column_name, value in old_row.items()}\n",
    "     return types.Row(**new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92d2c43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logarithmic_dataframe = df.rdd.map(take_log_in_all_columns).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb17c22",
   "metadata": {},
   "source": [
    "### sql functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06518ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb721f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   1|   2|\n",
      "|   4|   5|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"col1\", \"col2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef466d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   4|   5|   6|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"col1 = 4\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d124d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporal view\n",
    "df.createOrReplaceTempView(\"table1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2867cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform query on top of that view\n",
    "df2 = session.sql(\"SELECT col1 AS f1, col2 as f2 from table1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1c543ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| f1| f2|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "|  4|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f530ed",
   "metadata": {},
   "source": [
    "### column operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac704808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+--------------+\n",
      "|col1|col2|col3|derived_column|\n",
      "+----+----+----+--------------+\n",
      "|   1|   2|   3|             7|\n",
      "|   4|   5|   6|            34|\n",
      "+----+----+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df.withColumn(\"derived_column\", df[\"col1\"] + (df[\"col2\"] * df[\"col3\"]))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557cb7b",
   "metadata": {},
   "source": [
    "### aggregation and quick stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95e9c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADULT_COLUMN_NAMES = [\n",
    "     \"age\",\n",
    "     \"workclass\",\n",
    "     \"fnlwgt\",\n",
    "     \"education\",\n",
    "     \"education_num\",\n",
    "     \"marital_status\",\n",
    "     \"occupation\",\n",
    "     \"relationship\",\n",
    "     \"race\",\n",
    "     \"sex\",\n",
    "     \"capital_gain\",\n",
    "     \"capital_loss\",\n",
    "     \"hours_per_week\",\n",
    "     \"native_country\",\n",
    "     \"income\"\n",
    " ]\n",
    "\n",
    "csv_df = session.read.csv(\"adult.data.csv\", header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5241d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_col, old_col in zip(ADULT_COLUMN_NAMES, csv_df.columns):\n",
    "     csv_df = csv_df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d74a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|summary|               age|   workclass|            fnlwgt|    education|    education_num|marital_status|       occupation|relationship|               race|    sex|      capital_gain|    capital_loss|    hours_per_week|native_country|income|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|  count|             32561|       32561|             32561|        32561|            32561|         32561|            32561|       32561|              32561|  32561|             32561|           32561|             32561|         32561| 32561|\n",
      "|   mean| 38.58164675532078|        null|189778.36651208502|         null| 10.0806793403151|          null|             null|        null|               null|   null|1077.6488437087312| 87.303829734959|40.437455852092995|          null|  null|\n",
      "| stddev|13.640432553581356|        null|105549.97769702227|         null|2.572720332067397|          null|             null|        null|               null|   null| 7385.292084840354|402.960218649002|12.347428681731838|          null|  null|\n",
      "|    min|                17|           ?|           12285.0|         10th|              1.0|      Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|             0.0|               1.0|             ?| <=50K|\n",
      "|    max|                90| Without-pay|         1484705.0| Some-college|             16.0|       Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|          4356.0|              99.0|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64bd1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+---------------------------+\n",
      "|age|avg(hours_per_weeK)|stddev_samp(hours_per_week)|\n",
      "+---+-------------------+---------------------------+\n",
      "| 17| 21.367088607594937|         10.021014993616216|\n",
      "| 18| 25.912727272727274|         11.733362123434848|\n",
      "| 19| 30.678370786516854|         12.119154493614719|\n",
      "| 20|  32.28021248339974|         11.726599330994663|\n",
      "| 21|  34.03472222222222|         12.040389374051912|\n",
      "| 22|  35.17124183006536|         11.968466821743275|\n",
      "| 23|  36.71835803876853|         10.916632739093428|\n",
      "| 24|  39.08897243107769|         10.638975889466733|\n",
      "| 25|  40.00713436385256|         10.452953398659348|\n",
      "| 26|  41.06496815286624|          11.29552504314252|\n",
      "| 27| 42.039520958083834|         10.755941741375546|\n",
      "| 28|  42.02768166089965|         10.737113530868324|\n",
      "| 29|  42.36531365313653|         10.206157095904361|\n",
      "| 30| 42.167247386759584|         10.990266114829758|\n",
      "| 31| 42.877252252252255|         11.008740019442087|\n",
      "| 32| 42.878019323671495|          10.36006423810992|\n",
      "| 33| 42.965714285714284|         10.569643258593265|\n",
      "| 34|  42.93792325056433|         10.905945394498142|\n",
      "| 35|  43.90867579908676|         11.152690594723344|\n",
      "| 36|  43.25723830734967|         10.400753443197212|\n",
      "+---+-------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_hours_df = csv_df.groupBy(\"age\").agg(funcs.avg(\"hours_per_weeK\"), funcs.stddev_samp('hours_per_week')).sort(\"age\")\n",
    "work_hours_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0061a4",
   "metadata": {},
   "source": [
    "### Database connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e215b9",
   "metadata": {},
   "source": [
    "```python\n",
    "# create a session aware of the JDBC driver\n",
    "session = SparkSession.builder.config(\n",
    "    'spark.jars', 'bin/postgresql-42.2.16.jar'\n",
    ").config(\n",
    "    'spark.driver.extraClassPath', 'bin/postgresql-42.2.16.jar'\n",
    ").getOrCreate()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39a07b",
   "metadata": {},
   "source": [
    "```python\n",
    "# read from the database\n",
    "url = f\"jdbc:postgresql://your_host_ip:5432/your_database\"\n",
    "properties = {'user': 'your_user', 'password': 'your_password'}\n",
    "# read from a table into a dataframe\n",
    "df = session.read.jdbc(\n",
    "    url=url, table='your_table_name', properties=properties\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530289e8",
   "metadata": {},
   "source": [
    "```python\n",
    "### writing a pyspark dataframe to the database\n",
    "transformed_df.write.jdbc(\n",
    "    url=url, table='new_table', mode='append', properties=properties\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050e127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
