{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b637fe-c1df-4a4b-9ed8-ad3c431f6a0b",
   "metadata": {},
   "source": [
    "# First Agent In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5d3d7dc-a515-4444-975d-84c258f7e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_toytext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04ed3815-4bd7-4e27-b359-f7321ef9cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"NChain-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38e97d2b-2ec2-4313-af8a-3c241a34881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sum_reward_agent(env, num_episodes = 500):\n",
    "    r_table = np.zeros((5,2))\n",
    "    for g in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if np.sum(r_table[s, :]) == 0:\n",
    "                # make a random selection of actions\n",
    "                a = np.random.randint(0, 2)\n",
    "            else:\n",
    "                # select the action with highest cumulative reward\n",
    "                a = np.argmax(r_table[s, :])\n",
    "            new_s, r, done, _ = env.step(a)\n",
    "            r_table[s, a] += r\n",
    "            s = new_s\n",
    "    return r_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2e96eb0-df11-49e5-a269-329ef9a222e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 730 ms, sys: 25.7 ms, total: 755 ms\n",
      "Wall time: 739 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[     0., 122726.],\n",
       "       [     0.,  24822.],\n",
       "       [  1178.,      0.],\n",
       "       [     0.,   3896.],\n",
       "       [ 18774.,      0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reward_table = naive_sum_reward_agent(env, 100)\n",
    "reward_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa47e5b8-77ea-4335-a4c0-4dc5f11ff673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_with_table(env, num_episodes=100):\n",
    "    q_table = np.zeros((5,2))\n",
    "    y = 0.95\n",
    "    lr = 0.8\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if np.sum(q_table[s,:]) == 0:\n",
    "                # make a random selection of actions\n",
    "                a = np.random.randint(0, 2)\n",
    "            else:\n",
    "                # select the action with largest q value in state s\n",
    "                a = np.argmax(q_table[s, :])\n",
    "            new_s, r, done, _ = env.step(a)\n",
    "            q_table[s,a] += r + lr*(y*np.max(q_table[new_s, :]) - q_table[s,a])\n",
    "            s = new_s\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d67fd82-1bd3-4aeb-90db-01ae12186f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.1 s, sys: 34.5 ms, total: 5.13 s\n",
      "Wall time: 5.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 28.38378521],\n",
       "       [ 0.        , 27.67570783],\n",
       "       [ 0.        , 27.80012031],\n",
       "       [30.07206428,  0.        ],\n",
       "       [30.854693  ,  0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "q_learning_with_table(env, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2055b5be-54ff-45d7-a58f-63ba37f18486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy_q_learning_with_table(env, num_episodes=500):\n",
    "    q_table = np.zeros((5, 2))\n",
    "    y = 0.95\n",
    "    eps = 0.5\n",
    "    lr = 0.8\n",
    "    decay_factor = 0.999\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        eps *= decay_factor\n",
    "        done = False\n",
    "        while not done:\n",
    "            # select the action with highest cummulative reward\n",
    "            if np.random.random() < eps or np.sum(q_table[s, :]) == 0:\n",
    "                a = np.random.randint(0, 2)\n",
    "            else:\n",
    "                a = np.argmax(q_table[s, :])\n",
    "            # pdb.set_trace()\n",
    "            new_s, r, done, _ = env.step(a)\n",
    "            q_table[s, a] += r + lr * (y * np.max(q_table[new_s, :]) - q_table[s, a])\n",
    "            s = new_s\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32569ea2-2011-47ac-9cb8-e123d912fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.94 s, sys: 40.3 ms, total: 4.98 s\n",
      "Wall time: 4.97 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[60.95085983, 59.67865717],\n",
       "       [61.38658357, 60.04094886],\n",
       "       [62.67389025, 61.36423056],\n",
       "       [66.00436036, 64.91592648],\n",
       "       [62.56613276, 61.14965081]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "eps_greedy_q_learning_with_table(env, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a6325af-2694-40e5-b9a5-1545d4d91601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(table, env):\n",
    "    s = env.reset()\n",
    "    tot_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        a = np.argmax(table[s, :])\n",
    "        s, r, done, _ = env.step(a)\n",
    "        tot_reward += r\n",
    "    return tot_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c692e3c7-ce8c-47ba-be8c-d922ed2a3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_methods(env, num_iterations=100):\n",
    "    winner = np.zeros((3,))\n",
    "    for g in range(num_iterations):\n",
    "        if g % 10 == 0:\n",
    "            print(\"Game {} of {}\".format(g + 1, num_iterations))\n",
    "        # Train all models\n",
    "        m0_table = naive_sum_reward_agent(env, 500)\n",
    "        m1_table = q_learning_with_table(env, 500)\n",
    "        m2_table = eps_greedy_q_learning_with_table(env, 500)\n",
    "        # run a game with each model\n",
    "        m0_score = run_game(m0_table, env)\n",
    "        m1_score = run_game(m1_table, env)\n",
    "        m2_score = run_game(m2_table, env)\n",
    "        # determine which model got the most points, declare them as winner\n",
    "        w = np.argmax(np.array([m0_score, m1_score, m2_score]))\n",
    "        winner[w] += 1\n",
    "    print(\"Done\")\n",
    "    return winner\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "088b9e5c-cf5b-4685-92d9-5fcd46e81c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 1 of 100\n",
      "Game 11 of 100\n",
      "Game 21 of 100\n",
      "Game 31 of 100\n",
      "Game 41 of 100\n",
      "Game 51 of 100\n",
      "Game 61 of 100\n",
      "Game 71 of 100\n",
      "Game 81 of 100\n",
      "Game 91 of 100\n",
      "Done\n",
      "CPU times: user 21min 55s, sys: 3.48 s, total: 21min 58s\n",
      "Wall time: 21min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21., 12., 67.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "results = test_methods(env, 100)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff377e16-57b1-4fc5-a8cd-739a53d21161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
