{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d9d684-124d-4db8-af0b-097dc3430ccf",
   "metadata": {},
   "source": [
    "# NLP data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649613a-9806-44a5-a986-7aed1dd458c3",
   "metadata": {},
   "source": [
    "#### Loading the plain text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31923ad9-5d69-4dee-b9ca-7d13db2e344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "file = open(\"metamorphosis.txt\", \"rt\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123cfdee-d66d-4481-ae13-8144aaeb0371",
   "metadata": {},
   "source": [
    "#### split into words using whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af222294-ea50-4747-8dd7-7a979301ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "file = open(\"metamorphosis.txt\", \"rt\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "words = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96301b7-f69b-4f8d-8e97-a9564ea76483",
   "metadata": {},
   "source": [
    "> The punctuation is included with the word it's attached to which isn't ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bd0852-6977-4334-8b57-3ead83848af3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'morning,',\n",
       " 'when',\n",
       " 'Gregor',\n",
       " 'Samsa',\n",
       " 'woke',\n",
       " 'from',\n",
       " 'troubled',\n",
       " 'dreams,',\n",
       " 'he',\n",
       " 'found',\n",
       " 'himself',\n",
       " 'transformed',\n",
       " 'in',\n",
       " 'his',\n",
       " 'bed',\n",
       " 'into',\n",
       " 'a',\n",
       " 'horrible',\n",
       " 'vermin.',\n",
       " 'He',\n",
       " 'lay',\n",
       " 'on',\n",
       " 'his',\n",
       " 'armour-like',\n",
       " 'back,',\n",
       " 'and',\n",
       " 'if',\n",
       " 'he',\n",
       " 'lifted',\n",
       " 'his',\n",
       " 'head',\n",
       " 'a',\n",
       " 'little',\n",
       " 'he',\n",
       " 'could',\n",
       " 'see',\n",
       " 'his',\n",
       " 'brown',\n",
       " 'belly,',\n",
       " 'slightly',\n",
       " 'domed',\n",
       " 'and',\n",
       " 'divided',\n",
       " 'by',\n",
       " 'arches',\n",
       " 'into',\n",
       " 'stiff',\n",
       " 'sections.',\n",
       " 'The']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db273e5-4c19-4d50-87b6-46ee5ca30478",
   "metadata": {},
   "source": [
    "#### splitting into words using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fd4673-8f3e-423d-b5aa-9de9cc22ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "file = open(\"metamorphosis.txt\", \"rt\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "# splitting into words\n",
    "import re\n",
    "words = re.split(r\"\\W+\", text) # this regex selects alphanumeric characters only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c53c7-5102-4551-a9d9-87919ebc6e0b",
   "metadata": {},
   "source": [
    "> better but contractions are split into separate words.   \n",
    "> e.g. \"What's\" --> \"What\", \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc0cd02-4e5e-4c92-a624-7f9decdfe853",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waved',\n",
       " 'about',\n",
       " 'helplessly',\n",
       " 'as',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'What',\n",
       " 's',\n",
       " 'happened',\n",
       " 'to']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[80:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff332a-f1a3-4bc1-a813-ad2432557283",
   "metadata": {},
   "source": [
    "#### Split words by whitespace and then remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a4713-86ac-4768-88fe-2bfcecaa1170",
   "metadata": {},
   "source": [
    "Python provides a constant called string.punctuation that provides a great list of punctuation characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c6dd47-03a5-4017-99c9-42dcf13ebc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72eb85c8-415a-428f-8e85-c179a343b584",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 36: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 43: None,\n",
       " 44: None,\n",
       " 45: None,\n",
       " 46: None,\n",
       " 47: None,\n",
       " 58: None,\n",
       " 59: None,\n",
       " 60: None,\n",
       " 61: None,\n",
       " 62: None,\n",
       " 63: None,\n",
       " 64: None,\n",
       " 91: None,\n",
       " 92: None,\n",
       " 93: None,\n",
       " 94: None,\n",
       " 95: None,\n",
       " 96: None,\n",
       " 123: None,\n",
       " 124: None,\n",
       " 125: None,\n",
       " 126: None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numbers are ascii numbers for all the punctuation in the above string\n",
    "# this maps them to 'None' so effectively it removes them from the string\n",
    "str.maketrans(\"\", \"\", string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8450b7dd-7bb0-4bd8-bbec-064a43d70f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "file = open(\"metamorphosis.txt\", \"rt\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words and remove punctuation\n",
    "words = text.split()\n",
    "mapping = str.maketrans('', '', string.punctuation)\n",
    "words_stripped = [word.translate(mapping) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ac1f1d0-3891-4045-948b-9056472157c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35947387-3fa4-4bc6-8b64-e061db251ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'morning,',\n",
       " 'when',\n",
       " 'Gregor',\n",
       " 'Samsa',\n",
       " 'woke',\n",
       " 'from',\n",
       " 'troubled',\n",
       " 'dreams,',\n",
       " 'he',\n",
       " 'found',\n",
       " 'himself',\n",
       " 'transformed',\n",
       " 'in',\n",
       " 'his',\n",
       " 'bed',\n",
       " 'into',\n",
       " 'a',\n",
       " 'horrible',\n",
       " 'vermin.',\n",
       " 'He',\n",
       " 'lay',\n",
       " 'on',\n",
       " 'his',\n",
       " 'armour-like',\n",
       " 'back,',\n",
       " 'and',\n",
       " 'if',\n",
       " 'he',\n",
       " 'lifted',\n",
       " 'his',\n",
       " 'head',\n",
       " 'a',\n",
       " 'little',\n",
       " 'he',\n",
       " 'could',\n",
       " 'see',\n",
       " 'his',\n",
       " 'brown',\n",
       " 'belly,',\n",
       " 'slightly',\n",
       " 'domed',\n",
       " 'and',\n",
       " 'divided',\n",
       " 'by',\n",
       " 'arches',\n",
       " 'into',\n",
       " 'stiff',\n",
       " 'sections.',\n",
       " 'The',\n",
       " 'bedding',\n",
       " 'was',\n",
       " 'hardly',\n",
       " 'able',\n",
       " 'to',\n",
       " 'cover',\n",
       " 'it',\n",
       " 'and',\n",
       " 'seemed',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'slide',\n",
       " 'off',\n",
       " 'any',\n",
       " 'moment.',\n",
       " 'His',\n",
       " 'many',\n",
       " 'legs,',\n",
       " 'pitifully',\n",
       " 'thin',\n",
       " 'compared',\n",
       " 'with',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'him,',\n",
       " 'waved',\n",
       " 'about',\n",
       " 'helplessly',\n",
       " 'as',\n",
       " 'he',\n",
       " 'looked.',\n",
       " '“What’s',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'me?”',\n",
       " 'he',\n",
       " 'thought.',\n",
       " 'It',\n",
       " 'wasn’t',\n",
       " 'a',\n",
       " 'dream.',\n",
       " 'His',\n",
       " 'room,',\n",
       " 'a',\n",
       " 'proper',\n",
       " 'human',\n",
       " 'room',\n",
       " 'although',\n",
       " 'a',\n",
       " 'little',\n",
       " 'too',\n",
       " 'small,',\n",
       " 'lay',\n",
       " 'peacefully',\n",
       " 'between',\n",
       " 'its',\n",
       " 'four',\n",
       " 'familiar',\n",
       " 'walls.',\n",
       " 'A',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'textile',\n",
       " 'samples',\n",
       " 'lay',\n",
       " 'spread',\n",
       " 'out',\n",
       " 'on',\n",
       " 'the',\n",
       " 'table—Samsa',\n",
       " 'was',\n",
       " 'a',\n",
       " 'travelling',\n",
       " 'salesman—and',\n",
       " 'above',\n",
       " 'it',\n",
       " 'there',\n",
       " 'hung',\n",
       " 'a',\n",
       " 'picture',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'recently',\n",
       " 'cut',\n",
       " 'out',\n",
       " 'of',\n",
       " 'an',\n",
       " 'illustrated',\n",
       " 'magazine',\n",
       " 'and',\n",
       " 'housed',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nice,',\n",
       " 'gilded',\n",
       " 'frame.',\n",
       " 'It',\n",
       " 'showed',\n",
       " 'a',\n",
       " 'lady',\n",
       " 'fitted',\n",
       " 'out',\n",
       " 'with',\n",
       " 'a',\n",
       " 'fur',\n",
       " 'hat',\n",
       " 'and',\n",
       " 'fur',\n",
       " 'boa',\n",
       " 'who',\n",
       " 'sat',\n",
       " 'upright,',\n",
       " 'raising',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'fur',\n",
       " 'muff',\n",
       " 'that',\n",
       " 'covered',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'lower',\n",
       " 'arm',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'viewer.',\n",
       " 'Gregor',\n",
       " 'then',\n",
       " 'turned',\n",
       " 'to',\n",
       " 'look',\n",
       " 'out',\n",
       " 'the',\n",
       " 'window',\n",
       " 'at',\n",
       " 'the',\n",
       " 'dull',\n",
       " 'weather.',\n",
       " 'Drops',\n",
       " 'of',\n",
       " 'rain',\n",
       " 'could',\n",
       " 'be',\n",
       " 'heard',\n",
       " 'hitting',\n",
       " 'the',\n",
       " 'pane,',\n",
       " 'which',\n",
       " 'made',\n",
       " 'him',\n",
       " 'feel',\n",
       " 'quite',\n",
       " 'sad.',\n",
       " '“How',\n",
       " 'about',\n",
       " 'if',\n",
       " 'I',\n",
       " 'sleep',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'longer',\n",
       " 'and',\n",
       " 'forget',\n",
       " 'all',\n",
       " 'this',\n",
       " 'nonsense”,',\n",
       " 'he',\n",
       " 'thought,',\n",
       " 'but',\n",
       " 'that',\n",
       " 'was',\n",
       " 'something',\n",
       " 'he',\n",
       " 'was',\n",
       " 'unable',\n",
       " 'to',\n",
       " 'do',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'used',\n",
       " 'to',\n",
       " 'sleeping',\n",
       " 'on',\n",
       " 'his',\n",
       " 'right,',\n",
       " 'and',\n",
       " 'in',\n",
       " 'his',\n",
       " 'present',\n",
       " 'state',\n",
       " 'couldn’t',\n",
       " 'get',\n",
       " 'into',\n",
       " 'that',\n",
       " 'position.',\n",
       " 'However',\n",
       " 'hard',\n",
       " 'he',\n",
       " 'threw',\n",
       " 'himself',\n",
       " 'onto',\n",
       " 'his',\n",
       " 'right,',\n",
       " 'he',\n",
       " 'always',\n",
       " 'rolled',\n",
       " 'back',\n",
       " 'to',\n",
       " 'where',\n",
       " 'he',\n",
       " 'was.',\n",
       " 'He',\n",
       " 'must',\n",
       " 'have',\n",
       " 'tried',\n",
       " 'it',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'times,',\n",
       " 'shut',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'wouldn’t',\n",
       " 'have',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'floundering',\n",
       " 'legs,',\n",
       " 'and',\n",
       " 'only',\n",
       " 'stopped',\n",
       " 'when',\n",
       " 'he',\n",
       " 'began',\n",
       " 'to',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'mild,',\n",
       " 'dull',\n",
       " 'pain',\n",
       " 'there',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'never',\n",
       " 'felt',\n",
       " 'before.',\n",
       " '“Oh,',\n",
       " 'God”,',\n",
       " 'he',\n",
       " 'thought,',\n",
       " '“what',\n",
       " 'a',\n",
       " 'strenuous',\n",
       " 'career',\n",
       " 'it',\n",
       " 'is',\n",
       " 'that',\n",
       " 'I’ve',\n",
       " 'chosen!',\n",
       " 'Travelling',\n",
       " 'day',\n",
       " 'in',\n",
       " 'and',\n",
       " 'day',\n",
       " 'out.',\n",
       " 'Doing',\n",
       " 'business',\n",
       " 'like',\n",
       " 'this',\n",
       " 'takes',\n",
       " 'much',\n",
       " 'more',\n",
       " 'effort',\n",
       " 'than',\n",
       " 'doing',\n",
       " 'your',\n",
       " 'own',\n",
       " 'business',\n",
       " 'at',\n",
       " 'home,',\n",
       " 'and',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'that',\n",
       " 'there’s',\n",
       " 'the',\n",
       " 'curse',\n",
       " 'of',\n",
       " 'travelling,',\n",
       " 'worries',\n",
       " 'about',\n",
       " 'making',\n",
       " 'train',\n",
       " 'connections,',\n",
       " 'bad',\n",
       " 'and',\n",
       " 'irregular',\n",
       " 'food,',\n",
       " 'contact',\n",
       " 'with',\n",
       " 'different',\n",
       " 'people',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'so',\n",
       " 'that',\n",
       " 'you',\n",
       " 'can',\n",
       " 'never',\n",
       " 'get',\n",
       " 'to',\n",
       " 'know',\n",
       " 'anyone',\n",
       " 'or',\n",
       " 'become',\n",
       " 'friendly',\n",
       " 'with',\n",
       " 'them.',\n",
       " 'It',\n",
       " 'can',\n",
       " 'all',\n",
       " 'go',\n",
       " 'to',\n",
       " 'Hell!”',\n",
       " 'He',\n",
       " 'felt',\n",
       " 'a',\n",
       " 'slight',\n",
       " 'itch',\n",
       " 'up',\n",
       " 'on',\n",
       " 'his',\n",
       " 'belly;',\n",
       " 'pushed',\n",
       " 'himself',\n",
       " 'slowly',\n",
       " 'up',\n",
       " 'on',\n",
       " 'his',\n",
       " 'back',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'headboard',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'lift',\n",
       " 'his',\n",
       " 'head',\n",
       " 'better;',\n",
       " 'found',\n",
       " 'where',\n",
       " 'the',\n",
       " 'itch',\n",
       " 'was,',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'that',\n",
       " 'it',\n",
       " 'was',\n",
       " 'covered',\n",
       " 'with',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'little',\n",
       " 'white',\n",
       " 'spots',\n",
       " 'which',\n",
       " 'he',\n",
       " 'didn’t',\n",
       " 'know',\n",
       " 'what',\n",
       " 'to',\n",
       " 'make',\n",
       " 'of;',\n",
       " 'and',\n",
       " 'when',\n",
       " 'he',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'feel',\n",
       " 'the',\n",
       " 'place',\n",
       " 'with',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'legs',\n",
       " 'he',\n",
       " 'drew',\n",
       " 'it',\n",
       " 'quickly',\n",
       " 'back',\n",
       " 'because',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'he',\n",
       " 'touched',\n",
       " 'it',\n",
       " 'he',\n",
       " 'was',\n",
       " 'overcome',\n",
       " 'by',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'shudder.',\n",
       " 'He',\n",
       " 'slid',\n",
       " 'back',\n",
       " 'into',\n",
       " 'his',\n",
       " 'former',\n",
       " 'position.',\n",
       " '“Getting',\n",
       " 'up',\n",
       " 'early',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time”,',\n",
       " 'he',\n",
       " 'thought,',\n",
       " '“it',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'stupid.',\n",
       " 'You’ve',\n",
       " 'got',\n",
       " 'to',\n",
       " 'get',\n",
       " 'enough',\n",
       " 'sleep.',\n",
       " 'Other',\n",
       " 'travelling',\n",
       " 'salesmen',\n",
       " 'live',\n",
       " 'a',\n",
       " 'life',\n",
       " 'of',\n",
       " 'luxury.',\n",
       " 'For',\n",
       " 'instance,',\n",
       " 'whenever',\n",
       " 'I',\n",
       " 'go',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'guest',\n",
       " 'house',\n",
       " 'during',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'to',\n",
       " 'copy',\n",
       " 'out',\n",
       " 'the',\n",
       " 'contract,',\n",
       " 'these',\n",
       " 'gentlemen',\n",
       " 'are',\n",
       " 'always',\n",
       " 'still',\n",
       " 'sitting',\n",
       " 'there',\n",
       " 'eating',\n",
       " 'their',\n",
       " 'breakfasts.',\n",
       " 'I',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'just',\n",
       " 'try',\n",
       " 'that',\n",
       " 'with',\n",
       " 'my',\n",
       " 'boss;',\n",
       " 'I’d',\n",
       " 'get',\n",
       " 'kicked',\n",
       " 'out',\n",
       " 'on',\n",
       " 'the',\n",
       " 'spot.',\n",
       " 'But',\n",
       " 'who',\n",
       " 'knows,',\n",
       " 'maybe',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'the',\n",
       " 'best',\n",
       " 'thing',\n",
       " 'for',\n",
       " 'me.',\n",
       " 'If',\n",
       " 'I',\n",
       " 'didn’t',\n",
       " 'have',\n",
       " 'my',\n",
       " 'parents',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'I’d',\n",
       " 'have',\n",
       " 'given',\n",
       " 'in',\n",
       " 'my',\n",
       " 'notice',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " 'ago,',\n",
       " 'I’d',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'boss',\n",
       " 'and',\n",
       " 'told',\n",
       " 'him',\n",
       " 'just',\n",
       " 'what',\n",
       " 'I',\n",
       " 'think,',\n",
       " 'tell',\n",
       " 'him',\n",
       " 'everything',\n",
       " 'I',\n",
       " 'would,',\n",
       " 'let',\n",
       " 'him',\n",
       " 'know',\n",
       " 'just',\n",
       " 'what',\n",
       " 'I',\n",
       " 'feel.',\n",
       " 'He’d',\n",
       " 'fall',\n",
       " 'right',\n",
       " 'off',\n",
       " 'his',\n",
       " 'desk!',\n",
       " 'And',\n",
       " 'it’s',\n",
       " 'a',\n",
       " 'funny',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'business',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sitting',\n",
       " 'up',\n",
       " 'there',\n",
       " 'at',\n",
       " 'your',\n",
       " 'desk,',\n",
       " 'talking',\n",
       " 'down',\n",
       " 'at',\n",
       " 'your',\n",
       " 'subordinates',\n",
       " 'from',\n",
       " 'up',\n",
       " 'there,',\n",
       " 'especially',\n",
       " 'when',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'right',\n",
       " 'up',\n",
       " 'close',\n",
       " 'because',\n",
       " 'the',\n",
       " 'boss',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'of',\n",
       " 'hearing.',\n",
       " 'Well,',\n",
       " 'there’s',\n",
       " 'still',\n",
       " 'some',\n",
       " 'hope;',\n",
       " 'once',\n",
       " 'I’ve',\n",
       " 'got',\n",
       " 'the',\n",
       " 'money',\n",
       " 'together',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'off',\n",
       " 'my',\n",
       " 'parents’',\n",
       " 'debt',\n",
       " 'to',\n",
       " 'him—another',\n",
       " 'five',\n",
       " 'or',\n",
       " 'six',\n",
       " 'years',\n",
       " 'I',\n",
       " 'suppose—that’s',\n",
       " 'definitely',\n",
       " 'what',\n",
       " 'I’ll',\n",
       " 'do.',\n",
       " 'That’s',\n",
       " 'when',\n",
       " 'I’ll',\n",
       " 'make',\n",
       " 'the',\n",
       " 'big',\n",
       " 'change.',\n",
       " 'First',\n",
       " 'of',\n",
       " 'all',\n",
       " 'though,',\n",
       " 'I’ve',\n",
       " 'got',\n",
       " 'to',\n",
       " 'get',\n",
       " 'up,',\n",
       " 'my',\n",
       " 'train',\n",
       " 'leaves',\n",
       " 'at',\n",
       " 'five.”',\n",
       " 'And',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'over',\n",
       " 'at',\n",
       " 'the',\n",
       " 'alarm',\n",
       " 'clock,',\n",
       " 'ticking',\n",
       " 'on',\n",
       " 'the',\n",
       " 'chest',\n",
       " 'of',\n",
       " 'drawers.',\n",
       " '“God',\n",
       " 'in',\n",
       " 'Heaven!”',\n",
       " 'he',\n",
       " 'thought.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'half',\n",
       " 'past',\n",
       " 'six',\n",
       " 'and',\n",
       " 'the',\n",
       " 'hands',\n",
       " 'were',\n",
       " 'quietly',\n",
       " 'moving',\n",
       " 'forwards,',\n",
       " 'it',\n",
       " 'was',\n",
       " 'even',\n",
       " 'later',\n",
       " 'than',\n",
       " 'half',\n",
       " 'past,',\n",
       " 'more',\n",
       " 'like',\n",
       " 'quarter',\n",
       " 'to',\n",
       " 'seven.',\n",
       " 'Had',\n",
       " 'the',\n",
       " 'alarm',\n",
       " 'clock',\n",
       " 'not',\n",
       " 'rung?',\n",
       " 'He',\n",
       " 'could',\n",
       " 'see',\n",
       " 'from',\n",
       " 'the',\n",
       " 'bed',\n",
       " 'that',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'set',\n",
       " 'for',\n",
       " 'four',\n",
       " 'o’clock',\n",
       " 'as',\n",
       " 'it',\n",
       " 'should',\n",
       " 'have',\n",
       " 'been;',\n",
       " 'it',\n",
       " 'certainly',\n",
       " 'must',\n",
       " 'have',\n",
       " 'rung.',\n",
       " 'Yes,',\n",
       " 'but',\n",
       " 'was',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'quietly',\n",
       " 'sleep',\n",
       " 'through',\n",
       " 'that',\n",
       " 'furniture-rattling',\n",
       " 'noise?',\n",
       " 'True,',\n",
       " 'he',\n",
       " 'had',\n",
       " 'not',\n",
       " 'slept',\n",
       " 'peacefully,',\n",
       " 'but',\n",
       " 'probably',\n",
       " 'all',\n",
       " 'the',\n",
       " 'more',\n",
       " 'deeply',\n",
       " 'because',\n",
       " 'of',\n",
       " 'that.',\n",
       " 'What',\n",
       " 'should',\n",
       " 'he',\n",
       " 'do',\n",
       " 'now?',\n",
       " 'The',\n",
       " 'next',\n",
       " 'train',\n",
       " 'went',\n",
       " 'at',\n",
       " 'seven;',\n",
       " 'if',\n",
       " 'he',\n",
       " 'were',\n",
       " 'to',\n",
       " 'catch',\n",
       " 'that',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'to',\n",
       " 'rush',\n",
       " 'like',\n",
       " 'mad',\n",
       " 'and',\n",
       " 'the',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'samples',\n",
       " 'was',\n",
       " 'still',\n",
       " 'not',\n",
       " 'packed,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'did',\n",
       " 'not',\n",
       " 'at',\n",
       " 'all',\n",
       " 'feel',\n",
       " 'particularly',\n",
       " 'fresh',\n",
       " 'and',\n",
       " 'lively.',\n",
       " 'And',\n",
       " 'even',\n",
       " 'if',\n",
       " 'he',\n",
       " 'did',\n",
       " 'catch',\n",
       " 'the',\n",
       " 'train',\n",
       " 'he',\n",
       " 'would',\n",
       " 'not',\n",
       " 'avoid',\n",
       " 'his',\n",
       " 'boss’s',\n",
       " 'anger',\n",
       " 'as',\n",
       " 'the',\n",
       " 'office',\n",
       " 'assistant',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'there',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'five',\n",
       " 'o’clock',\n",
       " 'train',\n",
       " 'go,',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'put',\n",
       " 'in',\n",
       " 'his',\n",
       " 'report',\n",
       " 'about',\n",
       " 'Gregor’s',\n",
       " 'not',\n",
       " 'being',\n",
       " 'there',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " 'ago.',\n",
       " 'The',\n",
       " 'office',\n",
       " 'assistant',\n",
       " 'was',\n",
       " 'the',\n",
       " 'boss’s',\n",
       " 'man,',\n",
       " 'spineless,',\n",
       " 'and',\n",
       " 'with',\n",
       " 'no',\n",
       " 'understanding.',\n",
       " 'What',\n",
       " 'about',\n",
       " 'if',\n",
       " 'he',\n",
       " 'reported',\n",
       " 'sick?',\n",
       " 'But',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'extremely',\n",
       " 'strained',\n",
       " 'and',\n",
       " 'suspicious',\n",
       " 'as',\n",
       " 'in',\n",
       " 'five',\n",
       " 'years',\n",
       " 'of',\n",
       " 'service',\n",
       " 'Gregor',\n",
       " 'had',\n",
       " 'never',\n",
       " 'once',\n",
       " 'yet',\n",
       " 'been',\n",
       " 'ill.',\n",
       " 'His',\n",
       " 'boss',\n",
       " 'would',\n",
       " 'certainly',\n",
       " 'come',\n",
       " 'round',\n",
       " 'with',\n",
       " 'the',\n",
       " 'doctor',\n",
       " 'from',\n",
       " 'the',\n",
       " 'medical',\n",
       " 'insurance',\n",
       " 'company,',\n",
       " 'accuse',\n",
       " 'his',\n",
       " 'parents',\n",
       " 'of',\n",
       " 'having',\n",
       " 'a',\n",
       " 'lazy',\n",
       " 'son,',\n",
       " 'and',\n",
       " 'accept',\n",
       " 'the',\n",
       " 'doctor’s',\n",
       " 'recommendation',\n",
       " 'not',\n",
       " 'to',\n",
       " 'make',\n",
       " 'any',\n",
       " 'claim',\n",
       " 'as',\n",
       " 'the',\n",
       " 'doctor',\n",
       " 'believed',\n",
       " 'that',\n",
       " 'no-one',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'ill',\n",
       " 'but',\n",
       " 'that',\n",
       " 'many',\n",
       " 'were',\n",
       " 'workshy.',\n",
       " 'And',\n",
       " 'what’s',\n",
       " 'more,',\n",
       " 'would',\n",
       " 'he',\n",
       " 'have',\n",
       " 'been',\n",
       " 'entirely',\n",
       " 'wrong',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case?',\n",
       " 'Gregor',\n",
       " 'did',\n",
       " 'in',\n",
       " 'fact,',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'excessive',\n",
       " 'sleepiness',\n",
       " 'after',\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5312f7b2-f7b7-4872-9d9b-eb60eefaeb07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'morning',\n",
       " 'when',\n",
       " 'Gregor',\n",
       " 'Samsa',\n",
       " 'woke',\n",
       " 'from',\n",
       " 'troubled',\n",
       " 'dreams',\n",
       " 'he',\n",
       " 'found',\n",
       " 'himself',\n",
       " 'transformed',\n",
       " 'in',\n",
       " 'his',\n",
       " 'bed',\n",
       " 'into',\n",
       " 'a',\n",
       " 'horrible',\n",
       " 'vermin',\n",
       " 'He',\n",
       " 'lay',\n",
       " 'on',\n",
       " 'his',\n",
       " 'armourlike',\n",
       " 'back',\n",
       " 'and',\n",
       " 'if',\n",
       " 'he',\n",
       " 'lifted',\n",
       " 'his',\n",
       " 'head',\n",
       " 'a',\n",
       " 'little',\n",
       " 'he',\n",
       " 'could',\n",
       " 'see',\n",
       " 'his',\n",
       " 'brown',\n",
       " 'belly',\n",
       " 'slightly',\n",
       " 'domed',\n",
       " 'and',\n",
       " 'divided',\n",
       " 'by',\n",
       " 'arches',\n",
       " 'into',\n",
       " 'stiff',\n",
       " 'sections',\n",
       " 'The',\n",
       " 'bedding',\n",
       " 'was',\n",
       " 'hardly',\n",
       " 'able',\n",
       " 'to',\n",
       " 'cover',\n",
       " 'it',\n",
       " 'and',\n",
       " 'seemed',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'slide',\n",
       " 'off',\n",
       " 'any',\n",
       " 'moment',\n",
       " 'His',\n",
       " 'many',\n",
       " 'legs',\n",
       " 'pitifully',\n",
       " 'thin',\n",
       " 'compared',\n",
       " 'with',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'him',\n",
       " 'waved',\n",
       " 'about',\n",
       " 'helplessly',\n",
       " 'as',\n",
       " 'he',\n",
       " 'looked',\n",
       " '“What’s',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'me”',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'It',\n",
       " 'wasn’t',\n",
       " 'a',\n",
       " 'dream',\n",
       " 'His',\n",
       " 'room',\n",
       " 'a',\n",
       " 'proper',\n",
       " 'human']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_stripped[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2c132-9545-44c4-99bd-8cf5d11b5f05",
   "metadata": {},
   "source": [
    "> Note:   \n",
    "> It's common to convert all words to lower case.   \n",
    "> some meaning is lost, but the smaller vocabulary will be better for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663b448-53cd-48ea-b81c-3b819fcd0777",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177e081-76dd-4c39-85a0-98f80ff77f94",
   "metadata": {},
   "source": [
    "#### splitting data into sentences\n",
    "Many tasks prefer input to be in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6036e0db-3c1c-43cc-a7bb-3a7d6a918023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One morning, when Gregor Samsa woke from troubled dreams, he found\n",
      "himself transformed in his bed into a horrible vermin.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'metamorphosis.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into sentences\n",
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0ca4f-31ad-4935-b888-9c9324958961",
   "metadata": {},
   "source": [
    "> The newline character copied from the original plain text file is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa383c-26a1-4328-b330-cbf1bfcf7551",
   "metadata": {},
   "source": [
    "#### splitting into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "327c1794-cc51-4cb1-a809-308e53376056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '“', 'What', '’', 's', 'happened']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'metamorphosis.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into sentences\n",
    "from nltk import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479bc2cd-5933-4f25-8bb4-2088b020da3f",
   "metadata": {},
   "source": [
    "#### removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6f3ffcf-29ef-465a-a5c3-e907fff8d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 's', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasn', 't', 'a', 'dream', 'His', 'room', 'a', 'proper']\n"
     ]
    }
   ],
   "source": [
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6cf07-30e1-46fc-81de-dc8cc4697920",
   "metadata": {},
   "source": [
    "> What's still becomes What s   \n",
    "> also armour-like was removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53b2f4-d5bd-409c-829e-17e463d8c222",
   "metadata": {},
   "source": [
    "#### Filter out stop words\n",
    "Commonly agreed set of words that don't add semantic value to the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12ece140-0af0-4894-9af7-94fd7f175379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc65a6-c900-4db3-ac28-050fc0b24205",
   "metadata": {},
   "source": [
    "pipeline of text preparation:\n",
    "\n",
    "Load the raw text.  \n",
    "Split into tokens.  \n",
    "Convert to lowercase.  \n",
    "Remove punctuation from each token.  \n",
    "Filter out remaining tokens that are not alphabetic.  \n",
    "Filter out tokens that are stop words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c20f7a6c-33f2-4d16-a289-18c511c9a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armourlike', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', 'many', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 'happened', 'thought', 'dream', 'room', 'proper', 'human', 'room', 'although', 'little', 'small', 'lay', 'peacefully', 'four', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'travelling', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer', 'gregor', 'turned', 'look', 'window']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'metamorphosis.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94cc672-dbff-4e19-bbb7-afc6e2f8d5a6",
   "metadata": {},
   "source": [
    "#### Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9a39655-92d8-402f-bcfc-fe1a6392af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'morn', ',', 'when', 'gregor', 'samsa', 'woke', 'from', 'troubl', 'dream', ',', 'he', 'found', 'himself', 'transform', 'in', 'hi', 'bed', 'into', 'a', 'horribl', 'vermin', '.', 'he', 'lay', 'on', 'hi', 'armour-lik', 'back', ',', 'and', 'if', 'he', 'lift', 'hi', 'head', 'a', 'littl', 'he', 'could', 'see', 'hi', 'brown', 'belli', ',', 'slightli', 'dome', 'and', 'divid', 'by', 'arch', 'into', 'stiff', 'section', '.', 'the', 'bed', 'wa', 'hardli', 'abl', 'to', 'cover', 'it', 'and', 'seem', 'readi', 'to', 'slide', 'off', 'ani', 'moment', '.', 'hi', 'mani', 'leg', ',', 'piti', 'thin', 'compar', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'wave', 'about', 'helplessli', 'as', 'he', 'look', '.', '“', 'what', '’', 's', 'happen']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'metamorphosis.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# stemming of words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in tokens]\n",
    "print(stemmed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8425c3-a776-4559-9af9-23ed44f26f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
