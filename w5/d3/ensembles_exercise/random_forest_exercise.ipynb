{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Exercise\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:29.394687Z",
     "start_time": "2020-04-27T08:50:29.390791Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:30.089216Z",
     "start_time": "2020-04-27T08:50:29.632372Z"
    }
   },
   "outputs": [],
   "source": [
    "# list for column headers\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spend some time to explore the dataset.\n",
    "- head\n",
    "- shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:30.208854Z",
     "start_time": "2020-04-27T08:50:30.189089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create the X and y (the goal is to predict column **class** based on other variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:31.413192Z",
     "start_time": "2020-04-27T08:50:31.405951Z"
    }
   },
   "outputs": [],
   "source": [
    "features = df.columns[:-1]\n",
    "X = df[features]\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age\n",
       "0     6   148    72    35     0  33.6  0.627   50\n",
       "1     1    85    66    29     0  26.6  0.351   31\n",
       "2     8   183    64     0     0  23.3  0.672   32\n",
       "3     1    89    66    23    94  28.1  0.167   21\n",
       "4     0   137    40    35   168  43.1  2.288   33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* split data set into a train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:33.428446Z",
     "start_time": "2020-04-27T08:50:33.418848Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "#### Part 1: Setting up the Random Forest Classifier\n",
    "* import RandomForestClassifier from sklearn. It is suggested to spend some time on the doccumentation of this classifier to get familiar with the available parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:34.506151Z",
     "start_time": "2020-04-27T08:50:34.501702Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 1.0 (renaming of 0.25).\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0, 1)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:36.190876Z",
     "start_time": "2020-04-27T08:50:36.185977Z"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_make_estimator',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_oob_score',\n",
       " '_validate_X_predict',\n",
       " '_validate_data',\n",
       " '_validate_estimator',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'base_estimator',\n",
       " 'base_estimator_',\n",
       " 'bootstrap',\n",
       " 'ccp_alpha',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'criterion',\n",
       " 'decision_path',\n",
       " 'estimator_params',\n",
       " 'estimators_',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'max_samples',\n",
       " 'min_impurity_decrease',\n",
       " 'min_impurity_split',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'n_classes_',\n",
       " 'n_estimators',\n",
       " 'n_features_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_outputs_',\n",
       " 'oob_score',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fit training set with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:36.804671Z",
     "start_time": "2020-04-27T08:50:36.749655Z"
    }
   },
   "outputs": [],
   "source": [
    "forest = forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* predict X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:41.338777Z",
     "start_time": "2020-04-27T08:50:41.329305Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "y_proba = forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exploring results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_make_estimator',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_oob_score',\n",
       " '_validate_X_predict',\n",
       " '_validate_data',\n",
       " '_validate_estimator',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'base_estimator',\n",
       " 'base_estimator_',\n",
       " 'bootstrap',\n",
       " 'ccp_alpha',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'criterion',\n",
       " 'decision_path',\n",
       " 'estimator_params',\n",
       " 'estimators_',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'max_samples',\n",
       " 'min_impurity_decrease',\n",
       " 'min_impurity_split',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'n_classes_',\n",
       " 'n_estimators',\n",
       " 'n_features_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_outputs_',\n",
       " 'oob_score',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08713057, 0.26173161, 0.09039937, 0.06673977, 0.07635842,\n",
       "       0.15776609, 0.12179897, 0.13807519])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depths = [forest.estimators_[i].get_depth() for i in range(len(forest.estimators_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 17,\n",
       " 15,\n",
       " 14,\n",
       " 18,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 12,\n",
       " 14,\n",
       " 17,\n",
       " 14,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 18,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 17,\n",
       " 18,\n",
       " 14,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 14,\n",
       " 16,\n",
       " 16,\n",
       " 12,\n",
       " 17,\n",
       " 20,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 12,\n",
       " 18,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 18,\n",
       " 14,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 14]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import roc_auc_score and confusion_matrix from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:50:57.274676Z",
     "start_time": "2020-04-27T08:50:57.269456Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'RocCurveDisplay',\n",
       " 'SCORERS',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'plot_confusion_matrix',\n",
       " 'plot_det_curve',\n",
       " 'plot_precision_recall_curve',\n",
       " 'plot_roc_curve',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:51:13.303604Z",
     "start_time": "2020-04-27T08:51:13.293907Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics._classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
      "    \n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` and\n",
      "    predicted to be in group :math:`j`.\n",
      "    \n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,)\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : array-like of shape (n_samples,)\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array-like of shape (n_classes), default=None\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If ``None`` is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    normalize : {'true', 'pred', 'all'}, default=None\n",
      "        Normalizes confusion matrix over the true (rows), predicted (columns)\n",
      "        conditions or all the population. If None, confusion matrix will not be\n",
      "        normalized.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : ndarray of shape (n_classes, n_classes)\n",
      "        Confusion matrix whose i-th row and j-th\n",
      "        column entry indicates the number of\n",
      "        samples with true label being i-th class\n",
      "        and predicted label being j-th class.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    plot_confusion_matrix : Plot Confusion Matrix.\n",
      "    ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    In the binary case, we can extract true positives, etc as follows:\n",
      "    \n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 11],\n",
       "       [23, 29]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = metrics.confusion_matrix(y_test, y_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:53:24.047695Z",
     "start_time": "2020-04-27T08:53:24.039337Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_auc_score in module sklearn.metrics._ranking:\n",
      "\n",
      "roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)\n",
      "    Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
      "    from prediction scores.\n",
      "    \n",
      "    Note: this implementation can be used with binary, multiclass and\n",
      "    multilabel classification, but some restrictions apply (see Parameters).\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "        True labels or binary label indicators. The binary and multiclass cases\n",
      "        expect labels with shape (n_samples,) while the multilabel case expects\n",
      "        binary label indicators with shape (n_samples, n_classes).\n",
      "    \n",
      "    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "        Target scores.\n",
      "    \n",
      "        * In the binary case, it corresponds to an array of shape\n",
      "          `(n_samples,)`. Both probability estimates and non-thresholded\n",
      "          decision values can be provided. The probability estimates correspond\n",
      "          to the **probability of the class with the greater label**,\n",
      "          i.e. `estimator.classes_[1]` and thus\n",
      "          `estimator.predict_proba(X, y)[:, 1]`. The decision values\n",
      "          corresponds to the output of `estimator.decision_function(X, y)`.\n",
      "          See more information in the :ref:`User guide <roc_auc_binary>`;\n",
      "        * In the multiclass case, it corresponds to an array of shape\n",
      "          `(n_samples, n_classes)` of probability estimates provided by the\n",
      "          `predict_proba` method. The probability estimates **must**\n",
      "          sum to 1 across the possible classes. In addition, the order of the\n",
      "          class scores must correspond to the order of ``labels``,\n",
      "          if provided, or else to the numerical or lexicographical order of\n",
      "          the labels in ``y_true``. See more information in the\n",
      "          :ref:`User guide <roc_auc_multiclass>`;\n",
      "        * In the multilabel case, it corresponds to an array of shape\n",
      "          `(n_samples, n_classes)`. Probability estimates are provided by the\n",
      "          `predict_proba` method and the non-thresholded decision values by\n",
      "          the `decision_function` method. The probability estimates correspond\n",
      "          to the **probability of the class with the greater label for each\n",
      "          output** of the classifier. See more information in the\n",
      "          :ref:`User guide <roc_auc_multilabel>`.\n",
      "    \n",
      "    average : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'\n",
      "        If ``None``, the scores for each class are returned. Otherwise,\n",
      "        this determines the type of averaging performed on the data:\n",
      "        Note: multiclass ROC AUC currently only handles the 'macro' and\n",
      "        'weighted' averages.\n",
      "    \n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by considering each element of the label\n",
      "            indicator matrix as a label.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label).\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average.\n",
      "    \n",
      "        Will be ignored when ``y_true`` is binary.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    max_fpr : float > 0 and <= 1, default=None\n",
      "        If not ``None``, the standardized partial AUC [2]_ over the range\n",
      "        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n",
      "        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n",
      "        computation currently is not supported for multiclass.\n",
      "    \n",
      "    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n",
      "        Only used for multiclass targets. Determines the type of configuration\n",
      "        to use. The default value raises an error, so either\n",
      "        ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n",
      "    \n",
      "        ``'ovr'``:\n",
      "            Stands for One-vs-rest. Computes the AUC of each class\n",
      "            against the rest [3]_ [4]_. This\n",
      "            treats the multiclass case in the same way as the multilabel case.\n",
      "            Sensitive to class imbalance even when ``average == 'macro'``,\n",
      "            because class imbalance affects the composition of each of the\n",
      "            'rest' groupings.\n",
      "        ``'ovo'``:\n",
      "            Stands for One-vs-one. Computes the average AUC of all\n",
      "            possible pairwise combinations of classes [5]_.\n",
      "            Insensitive to class imbalance when\n",
      "            ``average == 'macro'``.\n",
      "    \n",
      "    labels : array-like of shape (n_classes,), default=None\n",
      "        Only used for multiclass targets. List of labels that index the\n",
      "        classes in ``y_score``. If ``None``, the numerical or lexicographical\n",
      "        order of the labels in ``y_true`` is used.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    auc : float\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n",
      "            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n",
      "    \n",
      "    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n",
      "           probability estimation trees (Section 6.2), CeDER Working Paper\n",
      "           #IS-00-04, Stern School of Business, New York University.\n",
      "    \n",
      "    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n",
      "            Recognition Letters, 27(8), 861-874.\n",
      "            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n",
      "    \n",
      "    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n",
      "            Under the ROC Curve for Multiple Class Classification Problems.\n",
      "            Machine Learning, 45(2), 171-186.\n",
      "            <http://link.springer.com/article/10.1023/A:1010920819831>`_\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    average_precision_score : Area under the precision-recall curve.\n",
      "    roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "    plot_roc_curve : Plot Receiver operating characteristic (ROC) curve.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Binary case:\n",
      "    \n",
      "    >>> from sklearn.datasets import load_breast_cancer\n",
      "    >>> from sklearn.linear_model import LogisticRegression\n",
      "    >>> from sklearn.metrics import roc_auc_score\n",
      "    >>> X, y = load_breast_cancer(return_X_y=True)\n",
      "    >>> clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
      "    0.99...\n",
      "    >>> roc_auc_score(y, clf.decision_function(X))\n",
      "    0.99...\n",
      "    \n",
      "    Multiclass case:\n",
      "    \n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> X, y = load_iris(return_X_y=True)\n",
      "    >>> clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n",
      "    0.99...\n",
      "    \n",
      "    Multilabel case:\n",
      "    \n",
      "    >>> from sklearn.datasets import make_multilabel_classification\n",
      "    >>> from sklearn.multioutput import MultiOutputClassifier\n",
      "    >>> X, y = make_multilabel_classification(random_state=0)\n",
      "    >>> clf = MultiOutputClassifier(clf).fit(X, y)\n",
      "    >>> # get a list of n_output containing probability arrays of shape\n",
      "    >>> # (n_samples, n_classes)\n",
      "    >>> y_pred = clf.predict_proba(X)\n",
      "    >>> # extract the positive columns for each output\n",
      "    >>> y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n",
      "    >>> roc_auc_score(y, y_pred, average=None)\n",
      "    array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])\n",
      "    >>> from sklearn.linear_model import RidgeClassifierCV\n",
      "    >>> clf = RidgeClassifierCV().fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.decision_function(X), average=None)\n",
      "    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503016591251886"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_curve in module sklearn.metrics._ranking:\n",
      "\n",
      "roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "    Compute Receiver operating characteristic (ROC).\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : ndarray of shape (n_samples,)\n",
      "        True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "        pos_label should be explicitly given.\n",
      "    \n",
      "    y_score : ndarray of shape (n_samples,)\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    pos_label : int or str, default=None\n",
      "        The label of the positive class.\n",
      "        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n",
      "        ``pos_label`` is set to 1, otherwise an error will be raised.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    drop_intermediate : bool, default=True\n",
      "        Whether to drop some suboptimal thresholds which would not appear\n",
      "        on a plotted ROC curve. This is useful in order to create lighter\n",
      "        ROC curves.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           parameter *drop_intermediate*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fpr : ndarray of shape (>2,)\n",
      "        Increasing false positive rates such that element i is the false\n",
      "        positive rate of predictions with score >= `thresholds[i]`.\n",
      "    \n",
      "    tpr : ndarray of shape (>2,)\n",
      "        Increasing true positive rates such that element `i` is the true\n",
      "        positive rate of predictions with score >= `thresholds[i]`.\n",
      "    \n",
      "    thresholds : ndarray of shape = (n_thresholds,)\n",
      "        Decreasing thresholds on the decision function used to compute\n",
      "        fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "        and is arbitrarily set to `max(y_score) + 1`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    plot_roc_curve : Plot Receiver operating characteristic (ROC) curve.\n",
      "    RocCurveDisplay : ROC Curve visualization.\n",
      "    det_curve: Compute error rates for different probability thresholds.\n",
      "    roc_auc_score : Compute the area under the ROC curve.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Since the thresholds are sorted from low to high values, they\n",
      "    are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "    and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
      "           Letters, 2006, 27(8):861-874.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "    >>> fpr\n",
      "    array([0. , 0. , 0.5, 0.5, 1. ])\n",
      "    >>> tpr\n",
      "    array([0. , 0.5, 0.5, 1. , 1. ])\n",
      "    >>> thresholds\n",
      "    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00980392, 0.00980392, 0.00980392, 0.01960784,\n",
       "       0.01960784, 0.01960784, 0.03921569, 0.03921569, 0.03921569,\n",
       "       0.04901961, 0.08823529, 0.08823529, 0.10784314, 0.12745098,\n",
       "       0.12745098, 0.14705882, 0.16666667, 0.16666667, 0.18627451,\n",
       "       0.19607843, 0.21568627, 0.23529412, 0.24509804, 0.24509804,\n",
       "       0.25490196, 0.26470588, 0.28431373, 0.31372549, 0.33333333,\n",
       "       0.34313725, 0.35294118, 0.38235294, 0.39215686, 0.41176471,\n",
       "       0.42156863, 0.44117647, 0.46078431, 0.5       , 0.50980392,\n",
       "       0.50980392, 0.53921569, 0.55882353, 0.58823529, 0.62745098,\n",
       "       0.64705882, 0.67647059, 0.75490196, 0.7745098 , 0.78431373,\n",
       "       0.80392157, 0.8627451 , 0.90196078, 0.96078431, 1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01923077, 0.05769231, 0.13461538, 0.15384615,\n",
       "       0.19230769, 0.25      , 0.30769231, 0.32692308, 0.34615385,\n",
       "       0.36538462, 0.42307692, 0.42307692, 0.46153846, 0.5       ,\n",
       "       0.51923077, 0.51923077, 0.53846154, 0.55769231, 0.55769231,\n",
       "       0.59615385, 0.59615385, 0.63461538, 0.67307692, 0.67307692,\n",
       "       0.67307692, 0.69230769, 0.69230769, 0.71153846, 0.73076923,\n",
       "       0.75      , 0.75      , 0.78846154, 0.78846154, 0.84615385,\n",
       "       0.86538462, 0.86538462, 0.86538462, 0.86538462, 0.88461538,\n",
       "       0.90384615, 0.90384615, 0.94230769, 0.94230769, 0.94230769,\n",
       "       0.96153846, 0.98076923, 0.98076923, 0.98076923, 0.98076923,\n",
       "       0.98076923, 0.98076923, 0.98076923, 0.98076923, 0.98076923,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.92, 0.92, 0.83, 0.76, 0.75, 0.73, 0.72, 0.71, 0.7 , 0.69, 0.66,\n",
       "       0.64, 0.6 , 0.58, 0.57, 0.56, 0.53, 0.52, 0.51, 0.49, 0.48, 0.46,\n",
       "       0.43, 0.41, 0.39, 0.38, 0.36, 0.35, 0.34, 0.33, 0.32, 0.31, 0.3 ,\n",
       "       0.29, 0.27, 0.26, 0.24, 0.23, 0.22, 0.21, 0.2 , 0.19, 0.18, 0.17,\n",
       "       0.16, 0.15, 0.14, 0.13, 0.12, 0.11, 0.1 , 0.09, 0.07, 0.06, 0.05,\n",
       "       0.04, 0.03, 0.02, 0.01, 0.  ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba[:,1])\n",
    "fpr\n",
    "tpr\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7fd072f69eb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(forest, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "#### Part 2: Using a Grid Search\n",
    "- import GridSearchCV from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:53:24.567027Z",
     "start_time": "2020-04-27T08:53:24.560156Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create grid (optimize for number of trees and max depth in one tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 12\n"
     ]
    }
   ],
   "source": [
    "depths = [forest.estimators_[i].get_depth() for i in range(len(forest.estimators_))]\n",
    "print(max(depths), min(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:53:25.754340Z",
     "start_time": "2020-04-27T08:53:25.747719Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\"n_estimators\": [10, 50, 100, 200], \"max_depth\": [12,14,16,18,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fit training data with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:55:29.610835Z",
     "start_time": "2020-04-27T08:54:05.136416Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7720111955217913"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=14, n_estimators=200)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T08:53:25.754340Z",
     "start_time": "2020-04-27T08:53:25.747719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [13, 14, 15],\n",
       "                         'n_estimators': [150, 200, 250]})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = {\"n_estimators\": [150, 200, 250], \"max_depth\": [13,14,15]}\n",
    "grid_search2 = GridSearchCV(estimator=RandomForestClassifier(), param_grid=grid2, n_jobs=-1)\n",
    "grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687724910035986"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=13, n_estimators=200)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13, 'n_estimators': 200}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_is_fitted',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_validate_data',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(grid_search2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train a new model with best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=14, n_estimators=200)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier(n_estimators=200, max_depth=14)\n",
    "forest2.fit(X_train, y_train)\n",
    "y_pred2 = forest2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print confusion matrix with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics._classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
      "    \n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` and\n",
      "    predicted to be in group :math:`j`.\n",
      "    \n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,)\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : array-like of shape (n_samples,)\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array-like of shape (n_classes), default=None\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If ``None`` is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    normalize : {'true', 'pred', 'all'}, default=None\n",
      "        Normalizes confusion matrix over the true (rows), predicted (columns)\n",
      "        conditions or all the population. If None, confusion matrix will not be\n",
      "        normalized.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : ndarray of shape (n_classes, n_classes)\n",
      "        Confusion matrix whose i-th row and j-th\n",
      "        column entry indicates the number of\n",
      "        samples with true label being i-th class\n",
      "        and predicted label being j-th class.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    plot_confusion_matrix : Plot Confusion Matrix.\n",
      "    ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    In the binary case, we can extract true positives, etc as follows:\n",
      "    \n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T14:32:48.798294Z",
     "start_time": "2020-02-27T14:32:48.712459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94,  8],\n",
       "       [23, 29]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf2 = metrics.confusion_matrix(y_test, y_pred2)\n",
    "cf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 11],\n",
       "       [23, 29]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print AUC with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T14:32:49.276652Z",
     "start_time": "2020-02-27T14:32:49.187448Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba2 = forest2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501131221719457"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forest2 model score\n",
    "metrics.roc_auc_score(y_test, y_proba2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503016591251886"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forest model score\n",
    "metrics.roc_auc_score(y_test, y_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- is the model better than default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are virtually the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forest2 classified 94 True postitives and 8 False positives  \n",
    "forest classified 91 True positives and 11 False positives\n",
    "\n",
    "all else was equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
