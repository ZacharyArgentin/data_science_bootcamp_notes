{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will try to predict credit card fraud.\n",
    "\n",
    "Download the data from [here](https://drive.google.com/file/d/1FCQY1SiWIjh_ME6Wtb3FG8Y1sKoRwAUc/view?usp=sharing). The data is originally from a [Kaggle Competition](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains transactions made by credit cards within two days in September 2013 by European cardholders.  Where **we have 492 occurrences of fraud out of the total of 284,807 transactions**. This dataset is highly unbalanced, with the positive class (frauds) account for 0.172% of all transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "### **Challenge:** Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features V1, V2, … V28 are the principal components obtained with PCA. The only features that are not transformed with PCA are `'Time'` and `'Amount'`.  \n",
    "\n",
    "- The feature `'Time'` contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The feature `'Amount'` is the transaction amount; this feature can be used for example-dependant cost-sensitive learning. \n",
    "- The feature `'Class'` is the target variable, and it takes the value of 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Warning\n",
    "> There is a huge class imbalance ratio, so we need to be careful when evaluating. It might be better to use the method `.predict_proba()` with a custom cut-off to search for fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/zacharyargentin/Programming/datasets/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(df[\"Amount\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9372636079788208, pvalue=2.9122073205463614e-31)\n",
      "ShapiroResult(statistic=0.7962122559547424, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.6862688064575195, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.8309727311134338, pvalue=1.401298464324817e-45)\n",
      "ShapiroResult(statistic=0.9564871788024902, pvalue=1.0561970067226685e-26)\n",
      "ShapiroResult(statistic=0.8983222842216492, pvalue=7.343748428226996e-38)\n",
      "ShapiroResult(statistic=0.8230225443840027, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.8109461665153503, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.5807204842567444, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.9823075532913208, pvalue=4.233689046058707e-17)\n",
      "ShapiroResult(statistic=0.8442113399505615, pvalue=3.0828566215145976e-44)\n",
      "ShapiroResult(statistic=0.9930910468101501, pvalue=1.6766561472536523e-09)\n",
      "ShapiroResult(statistic=0.8795782923698425, pvalue=2.4968055777646726e-40)\n",
      "ShapiroResult(statistic=0.9972802400588989, pvalue=0.0002135555405402556)\n",
      "ShapiroResult(statistic=0.951052188873291, pvalue=3.9665497391864607e-28)\n",
      "ShapiroResult(statistic=0.9907736778259277, pvalue=1.4166589776265504e-11)\n",
      "ShapiroResult(statistic=0.9707661867141724, pvalue=3.549022608587894e-22)\n",
      "ShapiroResult(statistic=0.8117721676826477, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.9918206930160522, pvalue=1.1040215269764175e-10)\n",
      "ShapiroResult(statistic=0.9834333658218384, pvalue=1.7326722004065736e-16)\n",
      "ShapiroResult(statistic=0.5900352597236633, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.5765753984451294, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.9714105129241943, pvalue=6.173261937154513e-22)\n",
      "ShapiroResult(statistic=0.6049240827560425, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.9747280478477478, pvalue=1.246218274748244e-20)\n",
      "ShapiroResult(statistic=0.9736640453338623, pvalue=4.613422555826567e-21)\n",
      "ShapiroResult(statistic=0.9740313291549683, pvalue=6.4794737591897906e-21)\n",
      "ShapiroResult(statistic=0.5003871917724609, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.3104560375213623, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.4110208749771118, pvalue=0.0)\n",
      "ShapiroResult(statistic=0.023510754108428955, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(st.shapiro(df[feature].sample(2500)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are no features from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Time\", \"Class\"], axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "a = scaler.fit_transform(X[\"Amount\"].values.reshape(-1,1))\n",
    "X[\"Amount\"] = pd.Series(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 s, sys: 720 ms, total: 5.77 s\n",
      "Wall time: 850 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_acc = accuracy_score(y_test, pred)\n",
    "lr_pre = precision_score(y_test, pred)\n",
    "lr_rec = recall_score(y_test, pred)\n",
    "lr_con = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99916903666772\n",
      "0.8347107438016529\n",
      "0.6644736842105263\n",
      "[[85271    20]\n",
      " [   51   101]]\n"
     ]
    }
   ],
   "source": [
    "print(lr_acc, lr_pre, lr_rec, lr_con, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 396 ms, total: 1min 49s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_acc = accuracy_score(y_test, pred)\n",
    "rf_pre = precision_score(y_test, pred)\n",
    "rf_rec = recall_score(y_test, pred)\n",
    "rf_con = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995084442259752\n",
      "0.9296875\n",
      "0.7828947368421053\n",
      "[[85282     9]\n",
      " [   33   119]]\n"
     ]
    }
   ],
   "source": [
    "print(rf_acc, rf_pre, rf_rec, rf_con, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67 ms, sys: 79.2 ms, total: 146 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_acc = accuracy_score(y_test, pred)\n",
    "nb_pre = precision_score(y_test, pred)\n",
    "nb_rec = recall_score(y_test, pred)\n",
    "nb_con = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977997027257938\n",
      "0.06319514661274014\n",
      "0.8223684210526315\n",
      "[[83438  1853]\n",
      " [   27   125]]\n"
     ]
    }
   ],
   "source": [
    "print(nb_acc, nb_pre, nb_rec, nb_con, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 2.52 s, total: 3min 19s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_acc = accuracy_score(y_test, pred)\n",
    "svc_pre = precision_score(y_test, pred)\n",
    "svc_rec = recall_score(y_test, pred)\n",
    "svc_con = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993445923013002\n",
      "0.9285714285714286\n",
      "0.6842105263157895\n",
      "[[85283     8]\n",
      " [   48   104]]\n"
     ]
    }
   ],
   "source": [
    "print(svc_acc, svc_pre, svc_rec, svc_con, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:56:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 1min 52s, sys: 2.73 s, total: 1min 55s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_acc = accuracy_score(y_test, pred)\n",
    "xgb_pre = precision_score(y_test, pred)\n",
    "xgb_rec = recall_score(y_test, pred)\n",
    "xgb_con = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995435553526912\n",
      "0.9312977099236641\n",
      "0.8026315789473685\n",
      "[[85282     9]\n",
      " [   30   122]]\n"
     ]
    }
   ],
   "source": [
    "print(xgb_acc, xgb_pre, xgb_rec, xgb_con, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion\n",
    "\n",
    "From just using basline models we could catch ~80% of fraudulent transactions\n",
    "\n",
    "xgboost was fast and accurate, precise, and high recall   \n",
    "random forest was slow, but accurate, precicse, and high recall.  \n",
    "naive bayes was lightning fast and had highest recall, but was less precise / accurate   \n",
    "svc was probably the worst model. slow and lower recall   \n",
    "logistic regression was like svc but lightning fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
